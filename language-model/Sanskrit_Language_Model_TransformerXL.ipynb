{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-sanskrit/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.tokenizer import SanskritTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inltk.tokenizer.SanskritTokenizer"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SanskritTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SanskritTokenizer(BaseTokenizer):\n",
    "#     def __init__(self, lang:str):\n",
    "#         self.lang = lang\n",
    "#         self.sp = spm.SentencePieceProcessor()\n",
    "#         self.sp.Load(str(path/\"../tokenizer/sanskrit_lm.model\"))\n",
    "        \n",
    "#     def tokenizer(self, t:str) -> List[str]:\n",
    "#         return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/sanskrit_lm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '▁।',\n",
       " '▁',\n",
       " 'ं',\n",
       " ',',\n",
       " 'ः',\n",
       " '-',\n",
       " 'म्',\n",
       " 'स्य',\n",
       " 'े',\n",
       " '▁च',\n",
       " '▁अस्ति',\n",
       " '।',\n",
       " '.',\n",
       " '▁इति',\n",
       " 'ा',\n",
       " '▁आसीत्',\n",
       " 'ाः']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20,000 is the vocab size that we chose in sentencepiece\n",
    "sanskrit_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=SanskritTokenizer, lang='sa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-sanskrit/language-model')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'transformer', tokenizer=tokenizer, vocab=sanskrit_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁1958 ▁तमे ▁वर्षे ▁अस्याः ▁संस्थायाः ▁संरचना ▁अभवत् ▁। ▁नासा ▁इत्येव ▁संक्षिप्त नाम्ना ▁अस्याः ▁ख्यातिः ▁। ▁नासा याः ▁मुख्यकार्यालय ः ▁वाशिङ् ग टन् , ▁डि . सि . ▁नगरे ▁अस्ति ▁। ▁1958 ▁ तमवर्षस्य ▁29 ▁तमे ▁दिनाङ्के ▁नै श नल् ▁ए ड् वै ज़ री ▁क मि टी ▁फ़ र् ▁ए रोनॉटिक ्स् ▁इति ▁अन्तरिक्ष संस्थायाः ▁अव लु प्त ि ं ▁कृत्वा ▁अमेरिका सर्वकारः ▁नै श नल् ▁ए रोनॉटिक ्स् ▁एण्ड्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁अस्य ▁मण्डलस्य ▁केन्द्रम् ▁अस्ति ▁ बह रै च ▁ x x bo s ▁ स्क्रिप्ट ▁त्रुटि : ▁\" &lt;unk&gt; &lt;unk&gt; ▁s hort ▁de script ion \" ▁ऐसा ▁कोई ▁मॉड ्यूल ▁नही ं ▁है । ▁ x x bo s ▁महाभारते ▁आदि पर्वणि ▁ शकुन ् ▁तल ा दु ष्यन् तयोः ▁कथा ▁लभते ▁। ▁शकुन्तला ▁ब्रह्म र्षे ः ▁विश्वामित्र स्य ▁स्वर्ग स्य ▁अ प्स रा याः , ▁मेन का याः ▁च</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁• ▁15 60 ▁• ▁15 61 ▁• ▁15 62 ▁• ▁15 63 ▁• ▁15 64 ▁• ▁15 65 ▁• ▁15 66 ▁• ▁15 67 ▁• ▁15 68 ▁• ▁15 6 9 ▁• ▁15 70 ▁• ▁15 71 ▁• ▁157 2 ▁• ▁15 73 ▁• ▁15 74 ▁• ▁15 75 ▁• ▁15 76 ▁• ▁15 77 ▁• ▁15 78 ▁• ▁15 79 ▁• ▁15 80 ▁• ▁15 81 ▁• ▁15 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁ x x bo s ▁ स्क्रिप्ट ▁त्रुटि : ▁\" &lt;unk&gt; &lt;unk&gt; ▁s hort ▁de script ion \" ▁ऐसा ▁कोई ▁मॉड ्यूल ▁नही ं ▁है । ▁गणित क्षेत्रे ▁भारतीय ानां ▁योगदानं ▁शून्य मिति ▁सर्व विदित म् ▁। ▁किन्तु ▁एतदतिरिच्य ापि ▁गणित क्षेत्रे ▁भारतस्य ▁योगदानं ▁विपुल ं ▁वर्तते ▁। ▁अपि ▁च ▁तस्य ▁योगदान स्य ▁प्रभावः ▁आधुनिक गणित शास्त्रे ▁अपि ▁ वरी वर्त्त ि ▁इत्येव ▁विशेषः ▁। ▁भारतीयसंस्कृतेः ▁विकासे ▁गणित म् ▁अपि</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>- नगरात् ▁देहली - नगरस्य ▁विमानस्थानकं ▁320 ▁किलोमीटर्मिते ▁दूरे ▁स्थितमस्ति ▁। ▁अनेन ▁जनाः ▁ग्वालियर - नगरं ▁सरलतया ▁प्राप्तुं ▁शक्नुवन्ति ▁। ▁मध्यप्रदेश - राज्ये ▁एकसदनात्मक ं ▁विधानमण्डल म् ▁अस्ति ▁। ▁राज्यस्य ▁विधानसभायाः ▁ सदस्यानां ▁सङ्ख्या ▁23 0 ▁अस्ति ▁। ▁राज्ये ▁लोकसभाया ः ▁29 ▁स्थानानि , ▁राज्यसभाया ः ▁11 ▁स्थानानि ▁च ▁सन्ति ▁। ▁“ प ं . ▁रविशङ्कर ▁शुक्ल ” ▁इत्याख्यः ▁मध्यप्रदेश - राज्यस्य ▁प्रथमः ▁मुख्यमन्त्री ▁आसीत् ▁। ▁“ प ं .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(20000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=20000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.154071</td>\n",
       "      <td>3.291768</td>\n",
       "      <td>0.564568</td>\n",
       "      <td>31:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.139888</td>\n",
       "      <td>2.835752</td>\n",
       "      <td>0.601113</td>\n",
       "      <td>31:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.474718</td>\n",
       "      <td>2.456913</td>\n",
       "      <td>0.632234</td>\n",
       "      <td>31:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.368002</td>\n",
       "      <td>2.282298</td>\n",
       "      <td>0.645209</td>\n",
       "      <td>31:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.302382</td>\n",
       "      <td>2.237828</td>\n",
       "      <td>0.644723</td>\n",
       "      <td>31:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.194650</td>\n",
       "      <td>2.134889</td>\n",
       "      <td>0.653257</td>\n",
       "      <td>31:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.963417</td>\n",
       "      <td>2.026230</td>\n",
       "      <td>0.665172</td>\n",
       "      <td>31:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.137518</td>\n",
       "      <td>1.933545</td>\n",
       "      <td>0.675175</td>\n",
       "      <td>31:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.993879</td>\n",
       "      <td>1.808482</td>\n",
       "      <td>0.692598</td>\n",
       "      <td>31:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.163775</td>\n",
       "      <td>1.705578</td>\n",
       "      <td>0.708088</td>\n",
       "      <td>31:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.817191</td>\n",
       "      <td>1.588199</td>\n",
       "      <td>0.726043</td>\n",
       "      <td>31:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.865462</td>\n",
       "      <td>1.475894</td>\n",
       "      <td>0.744257</td>\n",
       "      <td>31:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.538610</td>\n",
       "      <td>1.372166</td>\n",
       "      <td>0.761075</td>\n",
       "      <td>31:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.542283</td>\n",
       "      <td>1.282009</td>\n",
       "      <td>0.777208</td>\n",
       "      <td>31:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.529270</td>\n",
       "      <td>1.202274</td>\n",
       "      <td>0.791207</td>\n",
       "      <td>31:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.139415</td>\n",
       "      <td>1.133187</td>\n",
       "      <td>0.803651</td>\n",
       "      <td>31:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.143720</td>\n",
       "      <td>1.086020</td>\n",
       "      <td>0.812477</td>\n",
       "      <td>31:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.124093</td>\n",
       "      <td>1.047846</td>\n",
       "      <td>0.818979</td>\n",
       "      <td>31:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.024008</td>\n",
       "      <td>1.030698</td>\n",
       "      <td>0.821907</td>\n",
       "      <td>31:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.293110</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>0.822202</td>\n",
       "      <td>31:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.5645676255226135.\n",
      "Better model found at epoch 1 with accuracy value: 0.6011129021644592.\n",
      "Better model found at epoch 2 with accuracy value: 0.6322338581085205.\n",
      "Better model found at epoch 3 with accuracy value: 0.645209014415741.\n",
      "Better model found at epoch 5 with accuracy value: 0.6532570719718933.\n",
      "Better model found at epoch 6 with accuracy value: 0.6651723384857178.\n",
      "Better model found at epoch 7 with accuracy value: 0.6751745939254761.\n",
      "Better model found at epoch 8 with accuracy value: 0.6925978064537048.\n",
      "Better model found at epoch 9 with accuracy value: 0.7080881595611572.\n",
      "Better model found at epoch 10 with accuracy value: 0.7260430455207825.\n",
      "Better model found at epoch 11 with accuracy value: 0.7442565560340881.\n",
      "Better model found at epoch 12 with accuracy value: 0.7610749006271362.\n",
      "Better model found at epoch 13 with accuracy value: 0.7772083878517151.\n",
      "Better model found at epoch 14 with accuracy value: 0.7912068367004395.\n",
      "Better model found at epoch 15 with accuracy value: 0.8036509156227112.\n",
      "Better model found at epoch 16 with accuracy value: 0.8124772906303406.\n",
      "Better model found at epoch 17 with accuracy value: 0.8189786076545715.\n",
      "Better model found at epoch 18 with accuracy value: 0.8219068050384521.\n",
      "Better model found at epoch 19 with accuracy value: 0.822202205657959.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"तस्याः पिता\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "तस्याः पिता ▁महर्षिः ▁आसीत् । ▁ x x bo s ▁ स्क्रिप्ट ▁त्रुटि : ▁\" देश ▁देशस् ▁य ▁नगरः ▁अस् ▁ति । ▁अलाबामा ▁| ▁अलास्का ▁| ▁आर िज़ो ना ▁| ▁अर्कान्स ▁| ▁का लिफ़ ोर्निया ▁| ▁कोलोराडो ▁| ▁कनेक्टिकट् ▁| ▁डेला वेर्\n",
      "तस्याः पिता निर्व कोश िकः ▁कश्चन ▁शिक्षकः ▁। ▁तस्मिन् ▁चत्वारः ▁पादाः ▁सन्ति ▁। ▁तेषु ▁द्वौ ▁एवं ▁एकः ▁पुरुषः ▁। ▁ x x bo s ▁ स्क्रिप्ट ▁त्रुटि : ▁\" ▁\" ▁ ▁s hort ▁de script ion \" ▁ऐसा ▁कोई ▁मॉड ्यूल ▁नही\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7731947639642978"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-sanskrit/language-model')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'SanskritDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 410])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 410)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings_transformer.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.169647</td>\n",
       "      <td>0.058451</td>\n",
       "      <td>0.260510</td>\n",
       "      <td>0.467916</td>\n",
       "      <td>-0.419531</td>\n",
       "      <td>0.206374</td>\n",
       "      <td>0.170735</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>-0.291706</td>\n",
       "      <td>-0.247849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324177</td>\n",
       "      <td>-0.088940</td>\n",
       "      <td>-0.328013</td>\n",
       "      <td>0.051412</td>\n",
       "      <td>-0.166982</td>\n",
       "      <td>0.168031</td>\n",
       "      <td>-0.354324</td>\n",
       "      <td>0.213484</td>\n",
       "      <td>0.256730</td>\n",
       "      <td>-0.164348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.120863</td>\n",
       "      <td>0.455649</td>\n",
       "      <td>-0.011654</td>\n",
       "      <td>0.180977</td>\n",
       "      <td>-0.002927</td>\n",
       "      <td>-0.080978</td>\n",
       "      <td>-0.010470</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>-0.085018</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>0.126827</td>\n",
       "      <td>-0.062549</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>0.113766</td>\n",
       "      <td>-0.004518</td>\n",
       "      <td>0.166090</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>-0.054337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.116626</td>\n",
       "      <td>0.455841</td>\n",
       "      <td>-0.012514</td>\n",
       "      <td>0.174373</td>\n",
       "      <td>-0.003064</td>\n",
       "      <td>-0.081035</td>\n",
       "      <td>-0.020460</td>\n",
       "      <td>0.025402</td>\n",
       "      <td>-0.085098</td>\n",
       "      <td>0.033546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109770</td>\n",
       "      <td>0.063722</td>\n",
       "      <td>0.118362</td>\n",
       "      <td>-0.060914</td>\n",
       "      <td>0.171612</td>\n",
       "      <td>0.115609</td>\n",
       "      <td>-0.005279</td>\n",
       "      <td>0.171505</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>-0.055905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.221483</td>\n",
       "      <td>0.440458</td>\n",
       "      <td>-0.315887</td>\n",
       "      <td>-0.671472</td>\n",
       "      <td>-0.245623</td>\n",
       "      <td>-0.606604</td>\n",
       "      <td>-0.715155</td>\n",
       "      <td>-0.367341</td>\n",
       "      <td>-0.382365</td>\n",
       "      <td>0.196604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078364</td>\n",
       "      <td>-0.231544</td>\n",
       "      <td>0.304637</td>\n",
       "      <td>0.209951</td>\n",
       "      <td>0.022771</td>\n",
       "      <td>0.284060</td>\n",
       "      <td>0.039352</td>\n",
       "      <td>-0.286001</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>-0.116784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.018212</td>\n",
       "      <td>-0.581948</td>\n",
       "      <td>-0.056550</td>\n",
       "      <td>-0.489280</td>\n",
       "      <td>-0.059120</td>\n",
       "      <td>0.209476</td>\n",
       "      <td>0.066189</td>\n",
       "      <td>-0.034302</td>\n",
       "      <td>-0.007646</td>\n",
       "      <td>0.013580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006286</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>0.223081</td>\n",
       "      <td>-0.064937</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.059816</td>\n",
       "      <td>0.045514</td>\n",
       "      <td>-0.155628</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.056387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.169647  0.058451  0.260510  0.467916 -0.419531  0.206374  0.170735   \n",
       "1 -0.120863  0.455649 -0.011654  0.180977 -0.002927 -0.080978 -0.010470   \n",
       "2 -0.116626  0.455841 -0.012514  0.174373 -0.003064 -0.081035 -0.020460   \n",
       "3  0.221483  0.440458 -0.315887 -0.671472 -0.245623 -0.606604 -0.715155   \n",
       "4 -0.018212 -0.581948 -0.056550 -0.489280 -0.059120  0.209476  0.066189   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0  0.007706 -0.291706 -0.247849  ...  0.324177 -0.088940 -0.328013  0.051412   \n",
       "1  0.023015 -0.085018  0.027529  ...  0.110132  0.060216  0.126827 -0.062549   \n",
       "2  0.025402 -0.085098  0.033546  ...  0.109770  0.063722  0.118362 -0.060914   \n",
       "3 -0.367341 -0.382365  0.196604  ... -0.078364 -0.231544  0.304637  0.209951   \n",
       "4 -0.034302 -0.007646  0.013580  ... -0.006286 -0.001105  0.223081 -0.064937   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0 -0.166982  0.168031 -0.354324  0.213484  0.256730 -0.164348  \n",
       "1  0.172363  0.113766 -0.004518  0.166090 -0.001576 -0.054337  \n",
       "2  0.171612  0.115609 -0.005279  0.171505  0.001058 -0.055905  \n",
       "3  0.022771  0.284060  0.039352 -0.286001  0.013354 -0.116784  \n",
       "4  0.002001  0.059816  0.045514 -0.155628  0.002716  0.056387  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3     ▁।\n",
       "4      ▁"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_transformer_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2086e-01,  4.5565e-01, -1.1654e-02,  1.8098e-01, -2.9274e-03,\n",
       "        -8.0978e-02, -1.0470e-02,  2.3015e-02, -8.5018e-02,  2.7529e-02,\n",
       "         7.1904e-02, -1.2681e-02, -4.5343e-02, -4.0600e-02,  9.9447e-02,\n",
       "         6.7511e-02, -8.2244e-02, -3.6083e-02, -4.2622e-01, -8.3462e-03,\n",
       "        -2.7923e-02, -6.3987e-02,  7.1130e-02, -2.4661e-02,  8.9884e-02,\n",
       "         2.2581e-02, -4.9069e-02, -9.8187e-01,  2.6336e-02, -1.1168e-02,\n",
       "        -2.6739e-02, -3.7360e-03,  6.9202e-02,  6.2146e-02, -3.9030e-02,\n",
       "         9.4551e-03, -3.3869e-02, -4.1968e-02,  5.3545e-02,  5.8821e-02,\n",
       "        -2.4466e-02, -4.5772e-02, -3.7406e-02,  9.3826e-02,  8.4523e-02,\n",
       "        -1.3875e-02,  5.6811e-02, -1.4185e-01, -5.7414e-02,  7.6547e-02,\n",
       "        -1.0074e-01,  1.3376e-01, -5.5439e-03,  5.0898e-02, -1.6778e-01,\n",
       "         7.1110e-02, -8.4912e-02, -4.7950e-02, -2.2383e-02,  4.6031e-02,\n",
       "        -1.4019e-01, -1.5220e-01, -5.3084e-02,  5.9150e-02,  4.7171e-01,\n",
       "        -5.8124e-02, -3.5744e-02, -1.0121e-01, -3.6194e-02, -2.5696e-02,\n",
       "         9.0476e-02,  7.7397e-03, -2.0815e-02, -5.2923e-03, -2.6876e-02,\n",
       "        -1.7929e-02,  9.6086e-02,  8.6684e-02, -1.1989e-03, -9.9401e-02,\n",
       "        -1.0022e-01, -8.8259e-02, -1.3542e-01,  4.7062e-02, -3.3002e-02,\n",
       "        -1.6182e-02, -1.0430e-01, -4.9132e-02,  1.1666e-02, -6.6477e-02,\n",
       "        -9.6072e-03,  4.0587e-02,  5.0622e-02, -5.6399e-02,  2.3031e-02,\n",
       "        -9.0969e-03,  3.0558e-02, -1.6326e-02, -3.2880e-03, -6.0246e-02,\n",
       "        -2.3947e-03,  1.0031e-01, -7.4463e-02,  1.8474e-01, -9.4942e-02,\n",
       "         4.1492e-02,  6.6029e-02,  7.1495e-02, -1.4376e-01,  8.2768e-02,\n",
       "         1.0910e-01, -4.9958e-02,  1.1259e-02,  5.6036e-02,  2.3609e-02,\n",
       "         8.7627e-02, -2.8102e-02,  1.8642e-01, -1.4490e-01,  2.1474e-02,\n",
       "        -8.9904e-02,  1.8013e-01,  9.9802e-01, -6.7878e-03,  5.6272e-02,\n",
       "        -9.1335e-02, -4.2107e-02, -1.3022e-01, -5.9664e-02, -9.3989e-02,\n",
       "        -1.1275e-01,  4.9129e-02,  8.8892e-02,  2.8230e-02, -3.2351e-02,\n",
       "         2.9659e-02,  8.2812e-02, -2.1620e-02,  4.3131e-02,  3.6425e-03,\n",
       "         9.8896e-03, -1.6078e-01, -2.5760e-01,  8.8078e-02, -8.9825e-02,\n",
       "         1.6950e-01,  2.3883e-02,  5.0128e-02, -5.6006e-02, -9.8322e-02,\n",
       "         4.9722e-02,  1.0093e-01,  1.2380e-01,  7.4154e-02,  4.2136e-02,\n",
       "        -8.6191e-02, -2.5993e-02,  4.1112e-02,  3.8000e-02, -1.4829e-01,\n",
       "         2.9069e-01,  1.7590e-01,  1.4743e-02,  7.3674e-02, -1.6726e-03,\n",
       "        -9.0475e-02, -8.5545e-02,  4.9214e-02, -1.0857e-01, -2.0089e-02,\n",
       "        -7.9120e-02, -1.0049e-01, -5.5067e-02, -5.7571e-02,  5.6258e-02,\n",
       "        -1.6699e-01,  5.0127e-03,  1.5265e-01, -9.5362e-02, -9.7034e-02,\n",
       "         1.6036e-01, -5.1415e-02, -4.3330e-02,  3.2490e-01,  7.3623e-02,\n",
       "        -8.8315e-02, -7.0044e-02, -3.5064e-02, -1.3807e-02, -3.9051e-03,\n",
       "        -1.9446e-02, -2.7639e-02, -1.3792e-02,  3.4053e-02, -1.1763e-01,\n",
       "        -1.4747e-01,  1.5773e-01,  1.0836e-01, -1.1737e-01,  7.1113e-02,\n",
       "        -3.3897e-02,  3.6114e-02,  1.0765e-03,  8.9256e-02,  4.4344e-02,\n",
       "        -2.5200e-02, -1.3427e-01, -1.4651e-02,  1.7501e-01, -7.8188e-02,\n",
       "        -1.4254e-01,  1.9906e-02, -1.3614e-04,  4.1196e-03, -9.2116e-02,\n",
       "        -1.1176e-01,  1.5935e-01, -2.2327e-02, -1.1533e-01,  2.5281e-03,\n",
       "        -2.3441e-02, -2.8819e-02,  3.1666e-02, -1.2761e-01, -1.4803e-01,\n",
       "        -1.7433e-02, -2.9838e-02, -1.0278e-01,  2.2755e-01, -1.9238e-02,\n",
       "        -1.4848e-01,  5.5423e-02,  7.4030e-02,  3.6846e-02, -1.6466e-02,\n",
       "         1.7672e-02,  9.2271e-02,  1.2769e-01,  6.5398e-02,  1.1695e-01,\n",
       "         7.1774e-03, -5.6031e-02, -1.2296e-01, -5.0000e-03,  1.4662e-04,\n",
       "         1.2204e-02, -9.4824e-02,  2.6065e-02, -9.6521e-02,  7.6326e-02,\n",
       "         6.2912e-02, -7.7161e-02, -9.7560e-02,  9.1907e-02, -8.9641e-02,\n",
       "         3.2882e-02, -3.7394e-02, -1.1101e-01, -3.1704e-02,  8.6418e-02,\n",
       "         4.5220e-02,  4.6496e-02,  7.1071e-02, -4.2352e-02, -5.9849e-02,\n",
       "        -1.9734e-02,  7.8285e-02, -9.4402e-02, -3.4878e-02,  1.6737e-01,\n",
       "         4.7190e-02, -8.5959e-02, -6.0232e-02,  1.6742e-02, -1.3392e-01,\n",
       "         1.1466e-01,  1.2301e-01, -6.7409e-02, -3.4816e-02,  2.0012e-02,\n",
       "         9.3728e-02, -3.9577e-02,  1.8491e-01,  5.8197e-02, -1.2892e-02,\n",
       "         3.1407e-02,  1.3960e-01, -2.1034e-02, -3.9126e-02,  1.2174e-01,\n",
       "        -1.8894e-02, -3.1531e-02, -1.1171e-01,  3.4520e-02, -1.1942e-01,\n",
       "        -3.0171e-02, -1.0345e-01, -7.8632e-02,  6.2122e-02, -2.1082e-01,\n",
       "        -9.0542e-02, -4.5773e-01, -2.0771e-01, -4.5521e-02, -1.4831e-01,\n",
       "        -3.9205e-01,  3.4158e-02,  1.3704e-01, -1.6768e-02,  4.4341e-02,\n",
       "         8.3619e-02, -2.2898e-03, -5.3212e-02, -4.2159e-01, -8.0444e-02,\n",
       "         5.1395e-03, -8.0057e-03, -4.7695e-02,  1.5327e-01,  4.5558e-04,\n",
       "        -4.9907e-02, -1.7706e-01, -1.8784e-01,  1.0459e-01,  1.1689e-02,\n",
       "         5.3697e-02, -7.1101e-02,  3.3526e-02,  5.1682e-02, -1.3583e-01,\n",
       "        -1.0044e-02,  1.0958e-01, -1.0021e-02,  2.8910e-02,  1.1571e-01,\n",
       "        -1.6813e-01, -7.9703e-02, -3.3446e-02, -8.8426e-02, -9.0699e-03,\n",
       "         8.4828e-02, -1.6311e-02, -2.3577e-04,  5.8055e-02, -1.1305e-02,\n",
       "         3.0785e-02, -6.5279e-02, -1.1300e-01,  1.0489e-01, -2.5502e-02,\n",
       "         5.3772e-02, -1.0887e-02, -4.4605e-02,  3.9373e-01, -9.0637e-02,\n",
       "        -4.2655e-02,  1.3854e-01, -4.1349e-02,  1.1704e-01, -1.0738e-01,\n",
       "        -8.4641e-02, -6.4439e-02, -3.8302e-03,  7.7961e-02,  1.1328e-01,\n",
       "        -6.1434e-02,  1.6948e-02, -3.6555e-02, -4.2241e-03, -2.6105e-02,\n",
       "         2.7346e-02, -2.2259e-01, -8.4242e-02, -1.8126e-01, -1.0002e-01,\n",
       "         1.6105e-03,  5.3036e-02, -1.6499e-02, -4.1147e-02,  6.7752e-02,\n",
       "        -7.9107e-02, -3.9108e-02, -1.2389e-02, -1.7775e-02,  3.9540e-04,\n",
       "         8.6589e-02,  5.6800e-02,  3.0476e-03, -7.9257e-02,  5.1745e-02,\n",
       "        -3.4309e-02, -7.3610e-02, -3.5199e-02, -7.0285e-02,  6.9623e-02,\n",
       "        -5.5266e-02,  9.7405e-02,  1.2251e-01, -6.6231e-03, -8.2987e-02,\n",
       "         1.1013e-01,  6.0216e-02,  1.2683e-01, -6.2549e-02,  1.7236e-01,\n",
       "         1.1377e-01, -4.5182e-03,  1.6609e-01, -1.5762e-03, -5.4337e-02],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
